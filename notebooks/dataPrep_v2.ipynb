{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f930558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.optimize as sciopt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "\n",
    "import matplotlib.style as mplstyle\n",
    "mplstyle.use('fast')\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data will be located in the directory \"data_dir\", with filenames in the list \"data_files\". File extension may need to be changes, this code was written to run in a Linux environment\n",
    "import os\n",
    "data_dir = 'data/'\n",
    "data_files = [\"BH016-1_2GyroidPDMS-Dev_F200_coated_08_04_2024_Stability_in _gasToluene_Freq_stab_120sccm3X_5VPowerBank.txt\",\n",
    "              \"SS123-3_1-Dev_F200_coated_08_02_2024_Stability_in_gas_Toluene_Freq_stab_120sccm3X_5VPowerbank.txt\",\n",
    "              \"SS066-4_2-Gyroid75PUT-[Benchtop]Dev_F200OX_coated_10_26_2024_Stability_in _120sccm1XgasToluene_5VPowersupply2.txt\"]\n",
    "              # \"SS066-4_2-Gyroid75PUT-[Benchtop]Dev_F200OX_coated_10_28_2024_Stability_in _120sccmVsBlockPUT1XgasToluene_5VPowersupply.txt\"]\n",
    "              # \"SS066-4_2-Gyroid75PUT-[Benchtop]Dev_F200OX_coated_10_26_2024_Stability_in _120sccm1XgasToluene_5VPowersupply2.txt\",\n",
    "            #   \"SS123-3_1-Dev_F200_coated_03_12_2025_in_gasToluene_Freq_stab_120sccm10min1X_5VPowerSupply.txt\",\n",
    "\n",
    "nice_names = [\"PDMs Gyroid\",\n",
    "              \"Spraycoated\", #I think it's PDMS, but I need confirmation\n",
    "              \"PUT Gyroid\"]\n",
    "print(f'Your OS sees you\\'re current working directory location as \\\"{os.getcwd()}\\\" \\n from that location, files: \\n-  \\\"{'\\\"\\n-  \\\"'.join(data_files)}\\\"\\nshould be found in directory \\\"{data_dir}\\\" (with indices {[r for r in range(len(data_files))]} respectively)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data here\n",
    "#read all dataset files, and create a list of pandas dataframes, indexed by time relative to epoch time (for simplicity)\n",
    "datasets = []\n",
    "for file in data_files:\n",
    "    df = pd.read_csv(data_dir+file,sep ='\\t',engine='python',header=1,skipfooter=1)\n",
    "    df['datetime'] = pd.to_datetime(df['Time [ms]'],unit='ms')\n",
    "    df = df.set_index('datetime')\n",
    "    df['load'] = [[]] * len(df)\n",
    "    df['MFC [ml/min]'] = [[]] * len(df)\n",
    "    df['cycle_id'] = [[\"\"]] * len(df)\n",
    "    datasets.append(df)\n",
    "\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addloads(df,offset,period,load_cycle):\n",
    "    \n",
    "    y = df.resample(period,label='left',offset=offset)\n",
    "    # print(df.index.to_period('5m'))\n",
    "\n",
    "    df['load'] = [[]] * len(df)\n",
    "    df['MFC [ml/min]'] = [[]] * len(df)\n",
    "    df['cycle_id'] = [[\"\"]] * len(df)\n",
    "\n",
    "    for i,sample in enumerate(y):\n",
    "        # from the sample in y, get just the groups of points associated with the sample (the first index is just a timestamp)\n",
    "        group = sample[1]\n",
    "        #this command is a bit weird, it will calculate which index to pass to 'load_cycle' based on index 'i'. The interior most divmod() accounts for the 2 parts of each cycle (load and purge), the outer most accounts for the number of different loads encountered in one period of tests\n",
    "        cycle_divmod = divmod(divmod(i-1,2)[0],10)\n",
    "        \n",
    "        #assign the flow rate for the sample, making note that this assigns a nonzero flow rate to the purge cycle as well. I believe the purge data could have some use down the line, and would be most useful if the purge's history is known (i.e. what concentration it is pumping down from)\n",
    "        df.loc[group.index, 'MFC [ml/min]'] = [load_cycle[cycle_divmod[1]]] *  len(group)\n",
    "        #Toggle df field assignment based on whether purging or loading\n",
    "        if divmod(i+1,2)[1]==1: #purge\n",
    "            df.loc[group.index,'load'] = [False] * len(group) #False means no loading (purge)\n",
    "            #add unique descriptor to 'cycle_id'; this could be optimized if speed is an issue. For now, it's best to keep it human readable\n",
    "            df.loc[group.index,'cycle_id'] = [f'{'rising' if np.sign(np.real((-1)**(-(i-5)/10))) == 1 else 'falling'} cycle {divmod(divmod(i,2)[0],10)[0]+1}; purge from {load_cycle[cycle_divmod[1]]} ml/min.'] * len(group)\n",
    "        else: #load\n",
    "            df.loc[group.index,'load'] = [True] * len(group) #True means loading\n",
    "            #add unique descriptor to 'cycle_id'; this could be optimized if speed is an issue. For now, it's best to keep it human readable\n",
    "            df.loc[group.index,'cycle_id'] = [f'{'rising' if np.sign(np.real((-1)**(-(i-5)/10))) == 1 else 'falling'} cycle {divmod(divmod(i,2)[0],10)[0]+1}; {load_cycle[cycle_divmod[1]]} ml/min. load'] * len(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6137125",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up data here\n",
    "# initialize ramp rates\n",
    "load_ramp = [10,20,30,40,50] \n",
    "load_cycle = load_ramp+load_ramp[::-1] #the ramp down is just the mirror of the ramp up\n",
    "\n",
    "#set data offsets, and cycle periods. This will take some trial and error to get right, but plotly makes it easy to zoom and interact with your data\n",
    "offsets = ['1.50106min','3.47775min','3.16415min',f'{1.29528}min'] #'1.34286min'\n",
    "periods = ['5.001475927min'] * len(datasets) #same period used for all of the data\n",
    "load_cycles = [load_cycle] * len(datasets)\n",
    "# print()\n",
    "#don't worry about an output, the function applies updates directly to the dataframes you're feeding it from the `datasets` list\n",
    "_ = [addloads(df,offset,period,load_cycle) for (df,offset,period,load_cycle) in zip(datasets,offsets,periods,load_cycles)]\n",
    "\n",
    "\n",
    "#visualize in Plotly in one big plot\n",
    "fig = make_subplots(rows=1,cols=1)\n",
    "\n",
    "#for each dataframe (whole data now)\n",
    "for i,df in enumerate(datasets):\n",
    "    #filter by only the values in the dataframe where there is active loading, and is in 'cycle 1'\n",
    "    df_view = df.where(df['load']).where((df['cycle_id'].str.contains('cycle 1'))) # | df['cycle_id'].str.contains('cycle 2') #add this inside the parethesis of the rightmost .where() function if you want to look at the second cycle too\n",
    "    \n",
    "    #add the scattter plot to the plotly figure\n",
    "    fig.append_trace(go.Scatter(x = df_view.index - pd.to_timedelta(df_view['Time [ms]'].min(),unit='milliseconds'), #x = df_view['Time [ms]'].subtract(df_view['Time [ms]'].min()),\n",
    "                                y = df_view['Frequency [Hz]'].sub(df_view.loc[df['load']].iloc[0,1]),name=data_files[i][:7]),\n",
    "                                row=1,\n",
    "                                col=1)\n",
    "\n",
    "#export option is great if you want to pull up the plot in the browser, if you double-click the file in file explorer, it's likely your OS will automatically open it in the default browser app.\n",
    "fig.write_html('allDatapoints.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from notebooks import diffusionModel as diffmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def residual_eqn1(x,A,h,t,dm):#(D,A,h,t,f):\n",
    "    D = x[0]*1e-14\n",
    "    dt = x[1]\n",
    "    if dt<=0:\n",
    "        t_plus_dt = t+dt\n",
    "        idx = np.where(t_plus_dt>=0)[0]\n",
    "        t = t_plus_dt[idx]\n",
    "        dm = dm[idx]\n",
    "    attempt = diffmod.eqn1(D,A,h,t)\n",
    "    diff = np.diff(np.vstack((dm,attempt)),axis=0).squeeze()\n",
    "    rms_diff = np.sqrt(np.mean(np.square(diff)))\n",
    "    # print(diff.shape,dm.shape,attempt.shape)\n",
    "    # print(rms_diff,D*1e14)\n",
    "    return rms_diff\n",
    "\n",
    "# def residual_eqn3(D,A,h,t,dm):#(D,A,h,t,f):\n",
    "#     D = D*1e-14\n",
    "    \n",
    "#     attempt = diffmod.eqn3(D,A,h,t)\n",
    "#     diff = np.diff(np.vstack((dm,attempt)),axis=0).squeeze()\n",
    "#     rms_diff = np.sqrt(np.mean(np.square(diff)))\n",
    "#     # print(diff.shape,dm.shape,attempt.shape)\n",
    "#     # print(rms_diff,D*1e14)\n",
    "#     return rms_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb65839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit data to diffusion equations here\n",
    "D = 3e-8/(100**2) #m^/s diffusion coeff\n",
    "#arguments\n",
    "h = 5e-6 #meters, actual height of a hammerhead is ~5 um\n",
    "\n",
    "fig = make_subplots(rows=1,cols=1)\n",
    "output_fits = []\n",
    "\n",
    "for i,df in enumerate(datasets):\n",
    "    #filter dataframe by those in the VOC \"load\" phase for cycle 1. If multiple cycles are needed, add an OR operator (\"|\") and another \"(df['cycle_id'].str.contains('cycle #'))\"\n",
    "    df_filtered = df.loc[(df['load']) & \n",
    "                         (df['cycle_id'].str.contains('cycle 1'))]# &\n",
    "                        #  (df['MFC [ml/min]']==50)]\n",
    "    \n",
    "    #baseline frequency, the \"zero\" for all data. Taken at the start of the first load curve\n",
    "    f0 = df.loc[df['load']].iloc[0,1]\n",
    "\n",
    "    #concatenate unique names for all cycles in specified range\n",
    "    cycle_id = df_filtered['cycle_id'].unique()\n",
    "\n",
    "    for cid in cycle_id: #for each cycles we're interested in\n",
    "        #look at each curve individually\n",
    "        set_df = df_filtered.loc[(df['cycle_id']==cid)]\n",
    "        df_max = set_df['Frequency [Hz]'].sub(f0).min() #minimum bc it's in the negative direction\n",
    "        dm_max = -2*df_max\n",
    "        \n",
    "        #threshold for the two fits\n",
    "        set_0p5 = set_df.loc[set_df['Frequency [Hz]'].sub(f0) > 0.5*df_max]\n",
    "        set_0p8 = set_df.loc[set_df['Frequency [Hz]'].sub(f0) > 0.8*df_max]\n",
    "        \n",
    "        #convert to numpy arrays, with appropriate dm and t offsets\n",
    "        set_0p5_dm = set_0p5['Frequency [Hz]'].sub(f0).to_numpy()*-2\n",
    "        set_0p8_dm = set_0p8['Frequency [Hz]'].sub(f0).to_numpy()*-2\n",
    "        \n",
    "        set_0p5_t = set_0p5['Time [ms]'] - set_0p5['Time [ms]'].min()\n",
    "        set_0p8_t = set_0p8['Time [ms]'] - set_0p8['Time [ms]'].min()\n",
    "        set_0p5_t = set_0p5_t.to_numpy()/1000\n",
    "        set_0p8_t = set_0p8_t.to_numpy()/1000\n",
    "\n",
    "        #do fit for eqn 1; this part is heavy and would be more performant if parallelized, but the data handoff would take more code\n",
    "        res1 = sciopt.minimize(residual_eqn1,\n",
    "                                [D,-0.5],\n",
    "                                bounds=[(0.1,10000),(-1,10)],\n",
    "                                args=(dm_max,h,set_0p8_t,set_0p8_dm))\n",
    "        D_eff1 = res1.x[0]*1e-14\n",
    "        dt_eff1 = res1.x[1]*1e-14\n",
    "        r2_eqn1 = r2_score(set_0p8_dm,diffmod.eqn1(D_eff1,dm_max,h,set_0p8_t))\n",
    "\n",
    "        #do fit for eqn 3\n",
    "        p = np.polyfit(np.sqrt(set_0p5_t),set_0p5_dm,1)\n",
    "        r2_eqn3 = r2_score(set_0p5_dm,np.polyval(p,np.sqrt(set_0p5_t)))\n",
    "        D_eff3 = ((p[0]*h/(4*np.abs(df_max)))**2)*np.pi #the /1000 factor is to account for the time being in milliseconds\n",
    "        dt_eff3 = p[1]/p[0] #find the y-intercept; which is going to be an effective \"dt\" offset from what would be considered a real t0 for an ideal system\n",
    "\n",
    "        output_fits.append({'filename': data_files[i],\n",
    "                            'cycle_id': cid,\n",
    "                            'eqn1 Deff1 (cm^2/s)': D_eff1*(100**2),\n",
    "                            'eqn1 R^2': r2_eqn1,\n",
    "                            'eqn1 dt': dt_eff1,\n",
    "                            'eqn3 Deff3 (cm^2/s)': D_eff3*(100**2),\n",
    "                            'eqn3 R^2': r2_eqn3,\n",
    "                            'eqn3 dt': dt_eff3,\n",
    "                            'MFC [ml/min]': set_df['MFC [ml/min]'].unique()[0],\n",
    "                            'load': set_df['load'].unique()[0],\n",
    "                            'sampling period (min)': periods[i][:-3],\n",
    "                            'sampling offset (min)': offsets[i][:-3]})\n",
    "        # print(f'Eqn. 1; D = {D_eff1*(100**2)*(10**10)}x10^-10 cm^2/s; R^2 = {r2_eqn1}; dt = {dt_eff1}')\n",
    "        # print(f'Eqn. 3; D = {D_eff3*(100**2)*(10**10)}x10^-10 cm^2/s; R^2 = {r2_eqn3}; dt = {dt_eff3}')\n",
    "\n",
    "        # fig.append_trace(go.Scatter(x = set_df['Time [ms]'].div(1000) - set_df['Time [ms]'].min()/1000,\n",
    "        #                             y = -2*set_df['Frequency [Hz]'].sub(f0), name=data_files[i][:7]),\n",
    "        #                             row=1,\n",
    "        #                             col=1)\n",
    "        \n",
    "        # fig.append_trace(go.Scatter(x = set_0p5_t/1000-dt_eff3,\n",
    "        #                             y = diffmod.eqn3(Deff3,-2*df_max,h,set_0p5_t/1000-dt_eff3)+p[1],\n",
    "        #                             name='fit',\n",
    "        #                             # fill = 'black',\n",
    "        #                             line=dict(dash='dot',color='black')),\n",
    "        #                             row=1,\n",
    "        #                             col=1)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47433a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "# print(output_fits)\n",
    "\n",
    "output_file = data_dir + f'output_diffusion_fits_{datetime.now().strftime('%Y-%m-%d_%H:%M')}.csv'\n",
    "fieldnames = ['filename','cycle_id','eqn1 Deff1 (cm^2/s)','eqn1 R^2','eqn1 dt','eqn3 Deff3 (cm^2/s)','eqn3 R^2','eqn3 dt','MFC [ml/min]','load','sampling period (min)','sampling offset (min)']\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e39452",
   "metadata": {},
   "outputs": [],
   "source": [
    "##scratch\n",
    "# df = datasets[0]\n",
    "# print(np.sum(df['cycle_id'].str.contains('load').to_numpy()))\n",
    "df = datasets[0]\n",
    "# print(len(df.where(df['load'])))\n",
    "# print(df.loc[df['cycle_id'].str.contains('cycle 1')]['cycle_id'].unique())\n",
    "# print(len(df.loc[df['load'] & df['cycle_id'].str.contains('cycle 1')]))\n",
    "# print(datasets[0].index - pd.to_timedelta(datasets[0]['Time [ms]'].min(),unit='milliseconds'))\n",
    "# print(df['Frequency [Hz]'].sub(df.iloc[0,1]-1))\n",
    "# print([df['cycle_id'].uni?que() for df in datasets])\n",
    "# df.where(df['cycle_id'].str.contains('purge'))['Frequency [Hz]']\n",
    "# figure = px.scatter(df.where(df['cycle_id'].str.contains('purge'))['Frequency [Hz]'])\n",
    "\n",
    "# #scratch for data labelling\n",
    "# print(''.join([f'{'rising' if np.sign(np.real((-1)**(-(i-6)/10))) == 1 else 'falling'} cycle {divmod(divmod(i-1,2)[0],10)[0]+1}; purge from {load_cycle[divmod(divmod(i-2,2)[0],10)[1]]} ml/min.\\n' for i in range(25)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31097c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots everything you imported\n",
    "fig = make_subplots(rows=1,cols=1)\n",
    "\n",
    "for filename,df in zip(data_files,datasets):    \n",
    "    fig.append_trace(go.Scatter(x = df.index, y = df['Frequency [Hz]'].subtract(df.loc[df.index[0],'Frequency [Hz]']),),row=1,col=1)\n",
    "\n",
    "# fig.write_html('allDatapoints.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.loc[df.index[0],'Frequency [Hz]'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
